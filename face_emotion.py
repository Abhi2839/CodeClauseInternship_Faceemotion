# -*- coding: utf-8 -*-
"""face emotion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f_0dP442baHgtruoxvOAvra85uDVAIyI
"""

pip install deepface

import cv2
from deepface import DeepFace
import matplotlib.pyplot as plt

img=cv2.imread("/content/2.jpg")
plt.imshow(img)

"""converting bgr to rbg"""

plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))

"""using pre trained data"""

predictions=DeepFace.analyze(img)[0]
predictions

type(predictions)

faceCascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')
# cv2.CascadeClassifier
gray=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
faces=faceCascade.detectMultiScale(gray,1.1,4)
#drawing rect
for (x,y,w,h) in faces:
  cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),1)

# plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))

font=cv2.FONT_HERSHEY_COMPLEX
cv2.putText(img,predictions['dominant_emotion'],
(50,50),
font,1,(255,0,0),1,cv2.LINE_4
);
plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))
cv2.waitKey(0)
cv2.destroyAllWindows()

"""For 2nd img"""

img1=cv2.imread("/content/3.jpg")
plt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))

prediction1=DeepFace.analyze(img1)[0]
prediction1

"""Drawing rectangle across face using **Haar Algo**"""

faceCascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')
# cv2.CascadeClassifier
gray=cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)
faces=faceCascade.detectMultiScale(gray,1.1,4)
#drawing rect
for (x,y,w,h) in faces:
  cv2.rectangle(img1,(x,y),(x+w,y+h),(0,255,0),2)

plt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))

"""detecting emotion"""

font=cv2.FONT_HERSHEY_COMPLEX
cv2.putText(img1,prediction1['dominant_emotion'],
(50,50),
font,1,(250,0,0),1,cv2.LINE_4
);
plt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))
cv2.waitKey(0)
cv2.destroyAllWindows()

"""checking in realtime face emotion"""

import cv2
from deepface import DeepFace
faceCascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')

#opening web camera
cap=cv2.VideoCapture(0)
if not cap.isOpened():
  cap=cv2.VideoCapture(1)
if not cap.isOpened():
  raise IOError("Error while opening error Try Again.")
while True:
  #reading the face
  ret,frame=cap.read()
  result=DeepFace.analyze(frame,action=['emotion'])
  gray=cv2.cvtColor(frame,cv2.Color_BGR2RGB)
  faces=faceCascade.detectMultiScale(gray,1.1,4)
  #drawing rec aroung face
  for (x,y,w,h) in faces:
    cv2.rectangle(frame,(x,y),(x+w,y+w),(0,255,0),2)
  font=cv2.FONT_HERSHEY_COMPLEX
#adding text
  cv2.putText(
      frame,
      result['dominant_emotion'],(50,50),
      font ,2,(250,0,0),1,cv2.LINE_4
  );
  cv2.imshow("Frame ",frame)
  if cv2.waitKey(2) & 0xFF==ord('q'):
    break
cap.release()
cv2.destroyAllWindows()

import os
import cv2
from deepface import DeepFace

# Suppress TensorFlow logs
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# Loading Haar Cascade for face detection
faceCascade = cv2.CascadeClassifier(
    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
)

# Opening webcam
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    cap = cv2.VideoCapture(1)
if not cap.isOpened():
    raise IOError("Error while opening webcam. Try Again.")

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Convert to RGB for Haar detection
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Detect faces with Haar
    faces = faceCascade.detectMultiScale(gray, 1.1, 4)

    # Process each detected face
    for (x, y, w, h) in faces:
        # Extract the face region for DeepFace
        face_roi = frame[y:y+h, x:x+w]

        try:
            result = DeepFace.analyze(
                face_roi,
                actions=['emotion'],
                enforce_detection=False
            )[0]  # Pick first face result
            dominant_emotion = result['dominant_emotion']
        except Exception:
            dominant_emotion = "No Face"

        # Draw rectangle around face
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

        # Add emotion text
        font = cv2.FONT_HERSHEY_COMPLEX
        cv2.putText(
            frame,
            dominant_emotion,
            (x, y - 10),
            font,
            1,
            (250, 0, 0),
            2,
            cv2.LINE_4
        )

    # Show the output
    cv2.imshow("Emotion Detection", frame)

    # Exit on 'q'
    if cv2.waitKey(2) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

import matplotlib.pyplot as plt
import cv2
from deepface import DeepFace

img_url=input("Enter img url: ")

img_read=cv2.imread(img_url)
plt.imshow(cv2.cvtColor(img_read,cv2.COLOR_BGR2RGB))

prediction=DeepFace.analyze(img_read,actions=['emotion'],enforce_detection=False)

#drawing rect
faceCascade =cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')
gray=cv2.cvtColor(img_read,cv2.COLOR_BGR2GRAY)
face=faceCascade.detectMultiScale(gray,1.1,4)
for (x,y,w,h) in face:
    cv2.rectangle(img_read,(x,y),(x+w,y+h),(0,255,0),2)
# plt.imshow(cv2.cvtColor(img_read,cv2.COLOR_BGR2RGB))

#detecting emotion

font=cv2.FONT_HERSHEY_COMPLEX
cv2.putText(img_read,prediction['dominant_emotion'],
            (50,50),
            font,
            1,
            (255,0,0),1,cv2.LINE_4);

plt.imshow(cv2.cvtColor(img_read,cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.show()